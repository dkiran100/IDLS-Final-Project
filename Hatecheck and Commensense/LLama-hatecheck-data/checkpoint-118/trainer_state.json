{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 118,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08583690987124463,
      "grad_norm": 62.79646301269531,
      "learning_rate": 0.0001996917333733128,
      "loss": 24.2058,
      "step": 5
    },
    {
      "epoch": 0.17167381974248927,
      "grad_norm": 103.84671783447266,
      "learning_rate": 0.00019876883405951377,
      "loss": 25.4101,
      "step": 10
    },
    {
      "epoch": 0.2575107296137339,
      "grad_norm": 54.30069351196289,
      "learning_rate": 0.00019723699203976766,
      "loss": 24.8503,
      "step": 15
    },
    {
      "epoch": 0.34334763948497854,
      "grad_norm": 72.25271606445312,
      "learning_rate": 0.00019510565162951537,
      "loss": 23.2887,
      "step": 20
    },
    {
      "epoch": 0.4291845493562232,
      "grad_norm": 81.28648376464844,
      "learning_rate": 0.0001923879532511287,
      "loss": 23.2507,
      "step": 25
    },
    {
      "epoch": 0.5150214592274678,
      "grad_norm": 68.7068099975586,
      "learning_rate": 0.0001891006524188368,
      "loss": 23.8227,
      "step": 30
    },
    {
      "epoch": 0.6008583690987125,
      "grad_norm": 71.37512969970703,
      "learning_rate": 0.00018526401643540922,
      "loss": 21.7994,
      "step": 35
    },
    {
      "epoch": 0.6866952789699571,
      "grad_norm": 75.05928802490234,
      "learning_rate": 0.00018090169943749476,
      "loss": 22.7901,
      "step": 40
    },
    {
      "epoch": 0.7725321888412017,
      "grad_norm": 76.65218353271484,
      "learning_rate": 0.0001760405965600031,
      "loss": 21.1203,
      "step": 45
    },
    {
      "epoch": 0.8583690987124464,
      "grad_norm": 60.83210754394531,
      "learning_rate": 0.00017071067811865476,
      "loss": 21.6726,
      "step": 50
    },
    {
      "epoch": 0.944206008583691,
      "grad_norm": 71.9316635131836,
      "learning_rate": 0.00016494480483301836,
      "loss": 21.3944,
      "step": 55
    },
    {
      "epoch": 1.0171673819742488,
      "grad_norm": 67.06481170654297,
      "learning_rate": 0.00015877852522924732,
      "loss": 16.9749,
      "step": 60
    },
    {
      "epoch": 1.1030042918454936,
      "grad_norm": 97.86504364013672,
      "learning_rate": 0.0001522498564715949,
      "loss": 19.0235,
      "step": 65
    },
    {
      "epoch": 1.1888412017167382,
      "grad_norm": 53.650657653808594,
      "learning_rate": 0.00014539904997395468,
      "loss": 19.5931,
      "step": 70
    },
    {
      "epoch": 1.2746781115879828,
      "grad_norm": 65.0020751953125,
      "learning_rate": 0.000138268343236509,
      "loss": 20.1547,
      "step": 75
    },
    {
      "epoch": 1.3605150214592274,
      "grad_norm": 64.52494049072266,
      "learning_rate": 0.00013090169943749476,
      "loss": 19.003,
      "step": 80
    },
    {
      "epoch": 1.4463519313304722,
      "grad_norm": 69.77254486083984,
      "learning_rate": 0.00012334453638559057,
      "loss": 19.4515,
      "step": 85
    },
    {
      "epoch": 1.5321888412017168,
      "grad_norm": 58.58216094970703,
      "learning_rate": 0.0001156434465040231,
      "loss": 18.4268,
      "step": 90
    },
    {
      "epoch": 1.6180257510729614,
      "grad_norm": 59.35065841674805,
      "learning_rate": 0.0001078459095727845,
      "loss": 18.7417,
      "step": 95
    },
    {
      "epoch": 1.703862660944206,
      "grad_norm": 71.47188568115234,
      "learning_rate": 0.0001,
      "loss": 19.2967,
      "step": 100
    },
    {
      "epoch": 1.7896995708154506,
      "grad_norm": 59.06582260131836,
      "learning_rate": 9.215409042721552e-05,
      "loss": 18.0584,
      "step": 105
    },
    {
      "epoch": 1.8755364806866952,
      "grad_norm": 66.99595642089844,
      "learning_rate": 8.435655349597689e-05,
      "loss": 18.324,
      "step": 110
    },
    {
      "epoch": 1.9613733905579398,
      "grad_norm": 72.58490753173828,
      "learning_rate": 7.66554636144095e-05,
      "loss": 18.3635,
      "step": 115
    }
  ],
  "logging_steps": 5,
  "max_steps": 200,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.719770955204526e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
