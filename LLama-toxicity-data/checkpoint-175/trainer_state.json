{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.963350785340314,
  "eval_steps": 500,
  "global_step": 175,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.13961605584642234,
      "grad_norm": 0.8612110018730164,
      "learning_rate": 0.0001996917333733128,
      "loss": 1.452,
      "step": 5
    },
    {
      "epoch": 0.2792321116928447,
      "grad_norm": 0.9228360056877136,
      "learning_rate": 0.00019876883405951377,
      "loss": 1.3925,
      "step": 10
    },
    {
      "epoch": 0.418848167539267,
      "grad_norm": 0.9332492351531982,
      "learning_rate": 0.00019723699203976766,
      "loss": 1.3967,
      "step": 15
    },
    {
      "epoch": 0.5584642233856894,
      "grad_norm": 0.9063435196876526,
      "learning_rate": 0.00019510565162951537,
      "loss": 1.4496,
      "step": 20
    },
    {
      "epoch": 0.6980802792321117,
      "grad_norm": 0.8321095705032349,
      "learning_rate": 0.0001923879532511287,
      "loss": 1.4495,
      "step": 25
    },
    {
      "epoch": 0.837696335078534,
      "grad_norm": 0.8930559754371643,
      "learning_rate": 0.0001891006524188368,
      "loss": 1.3963,
      "step": 30
    },
    {
      "epoch": 0.9773123909249564,
      "grad_norm": 0.8614864945411682,
      "learning_rate": 0.00018526401643540922,
      "loss": 1.4034,
      "step": 35
    },
    {
      "epoch": 1.1361256544502618,
      "grad_norm": 0.8923763036727905,
      "learning_rate": 0.00018090169943749476,
      "loss": 1.5757,
      "step": 40
    },
    {
      "epoch": 1.2757417102966842,
      "grad_norm": 0.9601655006408691,
      "learning_rate": 0.0001760405965600031,
      "loss": 1.3514,
      "step": 45
    },
    {
      "epoch": 1.4153577661431065,
      "grad_norm": 1.007003664970398,
      "learning_rate": 0.00017071067811865476,
      "loss": 1.3859,
      "step": 50
    },
    {
      "epoch": 1.5549738219895288,
      "grad_norm": 0.9546681642532349,
      "learning_rate": 0.00016494480483301836,
      "loss": 1.3628,
      "step": 55
    },
    {
      "epoch": 1.6945898778359512,
      "grad_norm": 0.9159435033798218,
      "learning_rate": 0.00015877852522924732,
      "loss": 1.3781,
      "step": 60
    },
    {
      "epoch": 1.8342059336823735,
      "grad_norm": 0.9668905735015869,
      "learning_rate": 0.0001522498564715949,
      "loss": 1.3781,
      "step": 65
    },
    {
      "epoch": 1.9738219895287958,
      "grad_norm": 0.9983802437782288,
      "learning_rate": 0.00014539904997395468,
      "loss": 1.3511,
      "step": 70
    },
    {
      "epoch": 2.1326352530541013,
      "grad_norm": 1.0385383367538452,
      "learning_rate": 0.000138268343236509,
      "loss": 1.5167,
      "step": 75
    },
    {
      "epoch": 2.2722513089005236,
      "grad_norm": 1.146323561668396,
      "learning_rate": 0.00013090169943749476,
      "loss": 1.3232,
      "step": 80
    },
    {
      "epoch": 2.411867364746946,
      "grad_norm": 1.3792442083358765,
      "learning_rate": 0.00012334453638559057,
      "loss": 1.2975,
      "step": 85
    },
    {
      "epoch": 2.5514834205933683,
      "grad_norm": 1.1490678787231445,
      "learning_rate": 0.0001156434465040231,
      "loss": 1.3454,
      "step": 90
    },
    {
      "epoch": 2.6910994764397906,
      "grad_norm": 1.1380245685577393,
      "learning_rate": 0.0001078459095727845,
      "loss": 1.3142,
      "step": 95
    },
    {
      "epoch": 2.830715532286213,
      "grad_norm": 1.1093553304672241,
      "learning_rate": 0.0001,
      "loss": 1.3161,
      "step": 100
    },
    {
      "epoch": 2.9703315881326353,
      "grad_norm": 1.1119142770767212,
      "learning_rate": 9.215409042721552e-05,
      "loss": 1.3119,
      "step": 105
    },
    {
      "epoch": 3.1291448516579408,
      "grad_norm": 1.0713104009628296,
      "learning_rate": 8.435655349597689e-05,
      "loss": 1.4422,
      "step": 110
    },
    {
      "epoch": 3.268760907504363,
      "grad_norm": 1.183492660522461,
      "learning_rate": 7.66554636144095e-05,
      "loss": 1.2464,
      "step": 115
    },
    {
      "epoch": 3.4083769633507854,
      "grad_norm": 1.353331446647644,
      "learning_rate": 6.909830056250527e-05,
      "loss": 1.2723,
      "step": 120
    },
    {
      "epoch": 3.5479930191972078,
      "grad_norm": 1.2258063554763794,
      "learning_rate": 6.173165676349103e-05,
      "loss": 1.2785,
      "step": 125
    },
    {
      "epoch": 3.68760907504363,
      "grad_norm": 1.223990797996521,
      "learning_rate": 5.4600950026045326e-05,
      "loss": 1.2913,
      "step": 130
    },
    {
      "epoch": 3.8272251308900525,
      "grad_norm": 1.214028000831604,
      "learning_rate": 4.7750143528405126e-05,
      "loss": 1.2744,
      "step": 135
    },
    {
      "epoch": 3.966841186736475,
      "grad_norm": 1.1658904552459717,
      "learning_rate": 4.12214747707527e-05,
      "loss": 1.26,
      "step": 140
    },
    {
      "epoch": 4.12565445026178,
      "grad_norm": 1.307024359703064,
      "learning_rate": 3.5055195166981645e-05,
      "loss": 1.5247,
      "step": 145
    },
    {
      "epoch": 4.265270506108203,
      "grad_norm": 1.213081955909729,
      "learning_rate": 2.9289321881345254e-05,
      "loss": 1.234,
      "step": 150
    },
    {
      "epoch": 4.4048865619546245,
      "grad_norm": 1.3310130834579468,
      "learning_rate": 2.3959403439996907e-05,
      "loss": 1.2228,
      "step": 155
    },
    {
      "epoch": 4.544502617801047,
      "grad_norm": 1.3256545066833496,
      "learning_rate": 1.9098300562505266e-05,
      "loss": 1.2492,
      "step": 160
    },
    {
      "epoch": 4.684118673647469,
      "grad_norm": 1.2799551486968994,
      "learning_rate": 1.4735983564590783e-05,
      "loss": 1.2276,
      "step": 165
    },
    {
      "epoch": 4.823734729493892,
      "grad_norm": 1.289954423904419,
      "learning_rate": 1.0899347581163221e-05,
      "loss": 1.2317,
      "step": 170
    },
    {
      "epoch": 4.963350785340314,
      "grad_norm": 1.415616750717163,
      "learning_rate": 7.612046748871327e-06,
      "loss": 1.2539,
      "step": 175
    }
  ],
  "logging_steps": 5,
  "max_steps": 200,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 6,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.5925731674488832e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
